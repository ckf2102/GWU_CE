{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Merging, Cleaning Data Sets and Adding Variables#\n",
    "\n",
    "This notebook will be used to explore merging the data sets, cleaning the data sets (changing various values to np.NaN, converting fields to the appropriate value type), and adding calculated variables. The cleaned data st is exported as csv to be used in other data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cross = pd.read_csv('000_Cross-Sectional.csv', low_memory=False)\n",
    "base = pd.read_csv('00_Baseline.csv', low_memory=False)\n",
    "visit1 = pd.read_csv('01_Visit1.csv', low_memory=False)\n",
    "visit2 = pd.read_csv('02_Visit2.csv', low_memory=False)\n",
    "visit3 = pd.read_csv('03_Visit3.csv', low_memory=False)\n",
    "visit4 = pd.read_csv('04_Visit4.csv', low_memory=False)\n",
    "visit5 = pd.read_csv('05_Visit5.csv', low_memory=False)\n",
    "visit6 = pd.read_csv('06_Visit6.csv', low_memory=False)\n",
    "visit7 = pd.read_csv('07_Visit7.csv', low_memory=False)\n",
    "visit8 = pd.read_csv('08_Visit8.csv', low_memory=False)\n",
    "visit9 = pd.read_csv('09_Visit9.csv', low_memory=False)\n",
    "visit10 = pd.read_csv('10_Visit10.csv', low_memory=False)\n",
    "\n",
    "pd.set_option('display.max_rows', 120)\n",
    "cross.rename(columns={'ID':'SWANID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Merging Data Sets##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.merge(cross, base)\n",
    "data = pd.merge(data, visit1, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit2, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit3, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit4, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit5, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit6, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit7, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit8, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit9, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit10, on='SWANID', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3302, 9214)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Cleaning Data Sets##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Changing coded values for missing/null data to np.NaN###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.replace(' ', np.nan, inplace=True)\n",
    "data.replace('-9', np.nan, inplace=True)\n",
    "data.replace('-1', np.nan, inplace=True)\n",
    "data.replace('-7', np.nan, inplace=True)\n",
    "data.replace('-8', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Correcting data types###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrimination scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[['COURTES0', 'RESPECT0', 'POORSER0', 'NOTSMAR0', 'AFRAIDO0', 'DISHONS0', 'BETTER0', 'INSULTE0', 'HARASSE0', 'IGNORED0']] = data[['COURTES0', 'RESPECT0', 'POORSER0', 'NOTSMAR0', 'AFRAIDO0', 'DISHONS0', 'BETTER0', 'INSULTE0', 'HARASSE0', 'IGNORED0']].astype(float)\n",
    "data[['COURTES1', 'RESPECT1', 'POORSER1', 'NOTSMAR1', 'AFRAIDO1', 'DISHONS1', 'BETTER1', 'INSULTE1', 'HARASSE1', 'IGNORED1']] = data[['COURTES1', 'RESPECT1', 'POORSER1', 'NOTSMAR1', 'AFRAIDO1', 'DISHONS1', 'BETTER1', 'INSULTE1', 'HARASSE1', 'IGNORED1']].astype(float)\n",
    "data[['COURTES2', 'RESPECT2', 'POORSER2', 'NOTSMAR2', 'AFRAIDO2', 'DISHONS2', 'BETTER2', 'INSULTE2', 'HARASSE2', 'IGNORED2']] = data[['COURTES2', 'RESPECT2', 'POORSER2', 'NOTSMAR2', 'AFRAIDO2', 'DISHONS2', 'BETTER2', 'INSULTE2', 'HARASSE2', 'IGNORED2']].astype(float)\n",
    "data[['COURTES3', 'RESPECT3', 'POORSER3', 'NOTSMAR3', 'AFRAIDO3', 'DISHONS3', 'BETTER3', 'INSULTE3', 'HARASSE3', 'IGNORED3']] = data[['COURTES3', 'RESPECT3', 'POORSER3', 'NOTSMAR3', 'AFRAIDO3', 'DISHONS3', 'BETTER3', 'INSULTE3', 'HARASSE3', 'IGNORED3']].astype(float)\n",
    "data[['COURTES7', 'RESPECT7', 'POORSER7', 'NOTSMAR7', 'AFRAIDO7', 'DISHONS7', 'BETTER7', 'INSULTE7', 'HARASSE7', 'IGNORED7']] = data[['COURTES7', 'RESPECT7', 'POORSER7', 'NOTSMAR7', 'AFRAIDO7', 'DISHONS7', 'BETTER7', 'INSULTE7', 'HARASSE7', 'IGNORED7']].astype(float)\n",
    "data[['COURTES10', 'RESPECT10', 'POORSER10', 'NOTSMAR10', 'AFRAIDO10', 'DISHONS10', 'BETTER10', 'INSULTE10', 'HARASSE10', 'IGNORED10']] = data[['COURTES10', 'RESPECT10', 'POORSER10', 'NOTSMAR10', 'AFRAIDO10', 'DISHONS10', 'BETTER10', 'INSULTE10', 'HARASSE10', 'IGNORED10']].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[['AGE0', 'AGE1', 'AGE2', 'AGE3', 'AGE4', 'AGE5', 'AGE6', 'AGE7', 'AGE8', 'AGE9', 'AGE10']] = data[['AGE0', 'AGE1', 'AGE2', 'AGE3', 'AGE4', 'AGE5', 'AGE6', 'AGE7', 'AGE8', 'AGE9', 'AGE10']].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of days since baseline visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[['INTDAY1', 'INTDAY2', 'INTDAY3', 'INTDAY4', 'INTDAY5', 'INTDAY6', 'INTDAY7', 'INTDAY8', 'INTDAY9', 'INTDAY10']] = data[[\n",
    "        'INTDAY1', 'INTDAY2', 'INTDAY3', 'INTDAY4', 'INTDAY5', 'INTDAY6', 'INTDAY7', 'INTDAY8', \n",
    "        'INTDAY9', 'INTDAY10']].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[['BMI0']] = data[['BMI0']].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Adding Calculated Variables###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Average Discrimination Score*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[:, 'DISC_SCORE0'] = 5 - data[['COURTES0', 'RESPECT0', 'POORSER0', 'NOTSMAR0', 'AFRAIDO0', 'DISHONS0', \n",
    "                                   'BETTER0', 'INSULTE0', 'HARASSE0', 'IGNORED0']].mean(axis=1)\n",
    "data.loc[:, 'DISC_SCORE1'] = 5 - data[['COURTES1', 'RESPECT1', 'POORSER1', 'NOTSMAR1', 'AFRAIDO1', 'DISHONS1', \n",
    "                                   'BETTER1', 'INSULTE1', 'HARASSE1', 'IGNORED1']].mean(axis=1)\n",
    "data.loc[:, 'DISC_SCORE2'] = 5 - data[['COURTES2', 'RESPECT2', 'POORSER2', 'NOTSMAR2', 'AFRAIDO2', 'DISHONS2', \n",
    "                                    'BETTER2', 'INSULTE2', 'HARASSE2', 'IGNORED2']].mean(axis=1)\n",
    "data.loc[:, 'DISC_SCORE3'] = 5 - data[['COURTES3', 'RESPECT3', 'POORSER3', 'NOTSMAR3', 'AFRAIDO3', 'DISHONS3', \n",
    "                                    'BETTER3', 'INSULTE3', 'HARASSE3', 'IGNORED3']].mean(axis=1)\n",
    "data.loc[:, 'DISC_SCORE7'] = 5 - data[['COURTES7', 'RESPECT7', 'POORSER7', 'NOTSMAR7', 'AFRAIDO7', 'DISHONS7', \n",
    "                                    'BETTER7', 'INSULTE7', 'HARASSE7', 'IGNORED7']].mean(axis=1)\n",
    "data.loc[:, 'DISC_SCORE10'] = 5 - data[['COURTES10', 'RESPECT10', 'POORSER10', 'NOTSMAR10', 'AFRAIDO10', 'DISHONS10', \n",
    "                                    'BETTER10', 'INSULTE10', 'HARASSE10', 'IGNORED10']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Reason for Discrimination*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_binary(cols):\n",
    "    data[cols] = data[cols].map({'1':0, '2':1})\n",
    "    # data[cols].replace(np.nan, 0, inplace=True)\n",
    "    print data[cols].value_counts(dropna=False)\n",
    "\n",
    "def convert_binary_float(cols):\n",
    "    data[cols] = data[cols].map({1:0, 2:1})\n",
    "    # data[cols].replace(np.nan, 0, inplace=True) # this may need to come out for certain variables\n",
    "    print data[cols].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['RACE_REASON0'] = data.MAINREA0.map({'1':1, '2':1, '3':0, '4':0, '5':0, '6':0, '7':0, '8':0, '9':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN    2005\n",
      " 0      743\n",
      " 1      554\n",
      "Name: BCRACE1, dtype: int64\n",
      "NaN    2021\n",
      " 0      859\n",
      " 1      422\n",
      "Name: BCETHN1, dtype: int64\n",
      "NaN    2097\n",
      " 0      704\n",
      " 1      501\n",
      "Name: BCRACE2, dtype: int64\n",
      "NaN    2103\n",
      " 0      855\n",
      " 1      344\n",
      "Name: BCETHN2, dtype: int64\n",
      "NaN    2208\n",
      " 0      645\n",
      " 1      449\n",
      "Name: BCRACE3, dtype: int64\n",
      "NaN    2217\n",
      " 0      762\n",
      " 1      323\n",
      "Name: BCETHN3, dtype: int64\n",
      "NaN    2333\n",
      " 0      600\n",
      " 1      369\n",
      "Name: BCRACE7, dtype: int64\n",
      "NaN    2338\n",
      " 0      661\n",
      " 1      303\n",
      "Name: BCETHN7, dtype: int64\n",
      "NaN    2479\n",
      " 0      507\n",
      " 1      316\n",
      "Name: BCRACE10, dtype: int64\n",
      "NaN    2480\n",
      " 0      561\n",
      " 1      261\n",
      "Name: BCETHN10, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "race_conversion = ['BCRACE1', 'BCETHN1', 'BCRACE2', 'BCETHN2', 'BCRACE3', 'BCETHN3', \n",
    "                   'BCRACE7', 'BCETHN7', 'BCRACE10', 'BCETHN10']\n",
    "\n",
    "for x in race_conversion:\n",
    "    if(data[x].dtype == np.float64):\n",
    "            convert_binary_float(x)\n",
    "    else:\n",
    "        convert_binary(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[:, 'RACE_REASON1'] = data.BCRACE1 + data.BCETHN1\n",
    "data['RACE_REASON1'] = data.RACE_REASON1.map({0:0, 1:1, 2:1})\n",
    "\n",
    "data.loc[:, 'RACE_REASON2'] = data.BCRACE2 + data.BCETHN2\n",
    "data['RACE_REASON2'] = data.RACE_REASON2.map({0:0, 1:1, 2:1})\n",
    "\n",
    "data.loc[:, 'RACE_REASON3'] = data.BCRACE3 + data.BCETHN3\n",
    "data['RACE_REASON3'] = data.RACE_REASON3.map({0:0, 1:1, 2:1})\n",
    "\n",
    "data.loc[:, 'RACE_REASON7'] = data.BCRACE7 + data.BCETHN7\n",
    "data['RACE_REASON7'] = data.RACE_REASON7.map({0:0, 1:1, 2:1})\n",
    "\n",
    "data.loc[:, 'RACE_REASON10'] = data.BCRACE10 + data.BCETHN10\n",
    "data['RACE_REASON10'] = data.RACE_REASON10.map({0:0, 1:1, 2:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Outcome measures*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Difference between Lipid Vascular Age and actual age at each visit\n",
    "\n",
    "data['LV_AGE_DIFF0'] = data.LV_AGE0 - data.AGE0\n",
    "data['LV_AGE_DIFF1'] = data.LV_AGE1 - data.AGE1\n",
    "data['LV_AGE_DIFF3'] = data.LV_AGE3 - data.AGE3\n",
    "data['LV_AGE_DIFF4'] = data.LV_AGE4 - data.AGE4\n",
    "data['LV_AGE_DIFF5'] = data.LV_AGE5 - data.AGE5\n",
    "data['LV_AGE_DIFF6'] = data.LV_AGE6 - data.AGE6\n",
    "data['LV_AGE_DIFF7'] = data.LV_AGE7 - data.AGE7\n",
    "\n",
    "# Difference between BMI Vascular Age and actual age at each visit\n",
    "\n",
    "data['BV_AGE_DIFF0'] = data.BV_AGE0 - data.AGE0\n",
    "data['BV_AGE_DIFF1'] = data.BV_AGE1 - data.AGE1\n",
    "data['BV_AGE_DIFF2'] = data.BV_AGE2 - data.AGE2\n",
    "data['BV_AGE_DIFF3'] = data.BV_AGE3 - data.AGE3\n",
    "data['BV_AGE_DIFF4'] = data.BV_AGE4 - data.AGE4\n",
    "data['BV_AGE_DIFF5'] = data.BV_AGE5 - data.AGE5\n",
    "data['BV_AGE_DIFF6'] = data.BV_AGE6 - data.AGE6\n",
    "data['BV_AGE_DIFF7'] = data.BV_AGE7 - data.AGE7\n",
    "data['BV_AGE_DIFF8'] = data.BV_AGE8 - data.AGE8\n",
    "data['BV_AGE_DIFF9'] = data.BV_AGE9 - data.AGE9\n",
    "data['BV_AGE_DIFF10'] = data.BV_AGE10 - data.AGE10\n",
    "\n",
    "# Ratio of Change in Lipid Age from Visit X to Baseline to the number of days between Visit X and Baseline\n",
    "\n",
    "data['LV_AGE_RATIO1'] = (data.LV_AGE1 - data.LV_AGE0) / data.INTDAY1\n",
    "data['LV_AGE_RATIO3'] = (data.LV_AGE3 - data.LV_AGE0) / data.INTDAY3\n",
    "data['LV_AGE_RATIO4'] = (data.LV_AGE4 - data.LV_AGE0) / data.INTDAY4\n",
    "data['LV_AGE_RATIO5'] = (data.LV_AGE5 - data.LV_AGE0) / data.INTDAY5\n",
    "data['LV_AGE_RATIO6'] = (data.LV_AGE6 - data.LV_AGE0) / data.INTDAY6\n",
    "data['LV_AGE_RATIO7'] = (data.LV_AGE7 - data.LV_AGE0) / data.INTDAY7\n",
    "\n",
    "# Ratio of Change in BMI Age from Visit X to Baseline to the number of days between Visit X and Baseline\n",
    "\n",
    "data['BV_AGE_RATIO1'] = (data.BV_AGE1 - data.BV_AGE0) / data.INTDAY1\n",
    "data['BV_AGE_RATIO2'] = (data.BV_AGE2 - data.BV_AGE0) / data.INTDAY2\n",
    "data['BV_AGE_RATIO3'] = (data.BV_AGE3 - data.BV_AGE0) / data.INTDAY3\n",
    "data['BV_AGE_RATIO4'] = (data.BV_AGE4 - data.BV_AGE0) / data.INTDAY4\n",
    "data['BV_AGE_RATIO5'] = (data.BV_AGE5 - data.BV_AGE0) / data.INTDAY5\n",
    "data['BV_AGE_RATIO6'] = (data.BV_AGE6 - data.BV_AGE0) / data.INTDAY6\n",
    "data['BV_AGE_RATIO7'] = (data.BV_AGE7 - data.BV_AGE0) / data.INTDAY7\n",
    "data['BV_AGE_RATIO8'] = (data.BV_AGE8 - data.BV_AGE0) / data.INTDAY8\n",
    "data['BV_AGE_RATIO9'] = (data.BV_AGE9 - data.BV_AGE0) / data.INTDAY9\n",
    "data['BV_AGE_RATIO10'] = (data.BV_AGE10 - data.BV_AGE0) / data.INTDAY10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Replacing category numbers with names###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['RACE'] = data.ETHNIC.map({1:'Black', 8:'Asian', 9:'Asian', 10:'Caucasian', 13:'Hispanic'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BMI (putting into categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['BMI_CAT'] = data.BMI0\n",
    "\n",
    "data.loc[data.BMI_CAT < 18, ['BMI_CAT']] = 'Underweight'\n",
    "data.loc[data.BMI_CAT < 25, ['BMI_CAT']] = 'HealthyWeight'\n",
    "data.loc[data.BMI_CAT < 30, ['BMI_CAT']] = 'Overweight'\n",
    "data.loc[data.BMI_CAT < 100, ['BMI_CAT']] = 'Obese'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrimination scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['DISC_CAT'] = data.DISC_SCORE0\n",
    "\n",
    "data.loc[data.DISC_CAT >= 2.5, ['DISC_CAT']] = 'High'\n",
    "data.loc[data.DISC_CAT < 2.5, ['DISC_CAT']] = 'Low'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Writing to a new CSV###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.to_csv('991_CleanedData.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3302, 9263)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
