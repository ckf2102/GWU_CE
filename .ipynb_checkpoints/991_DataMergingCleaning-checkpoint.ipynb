{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Merging, Cleaning Data Sets and Adding Variables#\n",
    "\n",
    "This notebook will be used to explore merging the data sets, cleaning the data sets (changing various values to np.NaN, converting fields to the appropriate value type), and adding calculated variables. This code will be repeated in the exploratory and modeling notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cross = pd.read_csv('000_Cross-Sectional.csv', low_memory=False)\n",
    "base = pd.read_csv('00_Baseline.csv', low_memory=False)\n",
    "visit1 = pd.read_csv('01_Visit1.csv', low_memory=False)\n",
    "visit2 = pd.read_csv('02_Visit2.csv', low_memory=False)\n",
    "visit3 = pd.read_csv('03_Visit3.csv', low_memory=False)\n",
    "visit4 = pd.read_csv('04_Visit4.csv', low_memory=False)\n",
    "visit5 = pd.read_csv('05_Visit5.csv', low_memory=False)\n",
    "visit6 = pd.read_csv('06_Visit6.csv', low_memory=False)\n",
    "visit7 = pd.read_csv('07_Visit7.csv', low_memory=False)\n",
    "visit8 = pd.read_csv('08_Visit8.csv', low_memory=False)\n",
    "visit9 = pd.read_csv('09_Visit9.csv', low_memory=False)\n",
    "visit10 = pd.read_csv('10_Visit10.csv', low_memory=False)\n",
    "\n",
    "pd.set_option('display.max_rows', 120)\n",
    "cross.rename(columns={'ID':'SWANID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Merging Data Sets##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.merge(cross, base)\n",
    "data = pd.merge(data, visit1, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit2, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit3, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit4, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit5, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit6, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit7, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit8, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit9, on='SWANID', how='outer')\n",
    "data = pd.merge(data, visit10, on='SWANID', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3302, 9214)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Cleaning Data Sets##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Changing coded values for missing/null data to np.NaN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.replace(' ', np.nan, inplace=True)\n",
    "data.replace('-9', np.nan, inplace=True)\n",
    "data.replace('-1', np.nan, inplace=True)\n",
    "data.replace('-7', np.nan, inplace=True)\n",
    "data.replace('-8', np.nan, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
